{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18ee8c1",
   "metadata": {},
   "source": [
    "# Generaci√≥n de Datos Maestros de Clientes - ETL\n",
    "\n",
    "**Autor:** [Tu Nombre]  \n",
    "**Fecha:** 2026-02-21  \n",
    "**Versi√≥n:** 1.0\n",
    "\n",
    "## üìã Descripci√≥n General\n",
    "Este notebook ejecuta el proceso completo de Extracci√≥n, Transformaci√≥n y Carga (ETL) de datos maestros de clientes bancarios. Genera 100 registros sint√©ticos de clientes con datos realistas usando Faker, los transforma a trav√©s de tres zonas de datos (Raw, Curada y Productiva) aplicando estandarizaciones bancarias.\n",
    "\n",
    "## üéØ Objetivos\n",
    "1. Conectar a la base de datos PostgreSQL local con credenciales configuradas.\n",
    "2. Generar 100 registros de clientes sint√©ticos con datos bancarios realistas.\n",
    "3. Aplicar transformaciones y mapeos de columnas seg√∫n est√°ndares bancarios.\n",
    "4. Cargar datos en tres zonas: Raw (ZR), Curada (ZC) y Productiva (ZP).\n",
    "5. Crear dimensi√≥n de clientes optimizada para an√°lisis.\n",
    "6. Liberar recursos del sistema al finalizar.\n",
    "\n",
    "## ‚öôÔ∏è Requisitos Previos\n",
    "* **Librer√≠as:** `pandas`, `numpy`, `sqlalchemy`, `python-dotenv`, `faker`.\n",
    "* **Base de Datos:** PostgreSQL configurada con conexi√≥n local.\n",
    "* **Variables de entorno:** `.env` con credenciales (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME).\n",
    "* **Esquemas en PostgreSQL:** `zr_cli`, `zc_cli`, `zp` (deben existir).\n",
    "* **Archivos generados:** CSV en `data/raw/`, `data/curada/`, `data/productiva/`.\n",
    "\n",
    "## üìä Flujo de Datos\n",
    "```\n",
    "Generaci√≥n Faker (100 clientes sint√©ticos)\n",
    "    ‚Üì\n",
    "[Raw Zone] ‚Üí CSV y tabla td_datos_clientes ‚Üí zr_cli.zr_fake_cli_datos_clientes\n",
    "    ‚Üì\n",
    "[Curada Zone] ‚Üí Transformaci√≥n y normalizaci√≥n ‚Üí zc_cli.zc_cli_datos_clientes\n",
    "    ‚Üì\n",
    "[Productiva Zone] ‚Üí Dimensi√≥n optimizada ‚Üí zp.td_datos_clientes\n",
    "    ‚Üì\n",
    "Exportaci√≥n a CSV en zona productiva\n",
    "```\n",
    "\n",
    "## üîë Campos Principales Generados\n",
    "- `codigoSecuencialCliente`: Identificador secuencial (1000-1099)\n",
    "- `codigoIdentificacionCliente`: C√≥digo √∫nico (CUS-XXXXX)\n",
    "- `tipoIdentificacionCliente`: C√âDULA, RUC o PASAPORTE\n",
    "- `numeroIdentificacionCliente`: N√∫mero √∫nico de ID\n",
    "- `nombreCompletoCliente`: Nombre del cliente (generado con Faker)\n",
    "- `segmentoCliente`: RETAIL, CORPORATIVO, PYME, WEALTH\n",
    "- `scoreCrediticioCliente`: Score entre 300 y 1000\n",
    "- `provinciaCliente`: Pichincha, Guayas, Azuay, Manab√≠, Loja\n",
    "- `ciudadCliente`: Quito, Guayaquil, Cuenca, Manta\n",
    "- `fechaRegistroCliente`: Fecha aleatoria (√∫ltimos 5 a√±os)\n",
    "\n",
    "## ‚ö†Ô∏è Notas Importantes\n",
    "- Los datos son 100% sint√©ticos para POC/testing\n",
    "- Utiliza Faker con seed=42 para reproducibilidad\n",
    "- Implementa transformaciones case-insensitive (may√∫sculas)\n",
    "- Las fechas se convierten a formato DATE en PostgreSQL para consistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9e742977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .dataframe {\n",
       "            border-collapse: collapse;\n",
       "            border: 2px solid #1a237e; /* Azul Marino Bancario */\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            font-size: 12px;\n",
       "        }\n",
       "        .dataframe thead {\n",
       "            background-color: #1a237e;\n",
       "            color: white;\n",
       "            text-align: center;\n",
       "        }\n",
       "        .dataframe th, .dataframe td {\n",
       "            padding: 10px 15px;\n",
       "            border: 1px solid #e0e0e0;\n",
       "        }\n",
       "        .dataframe tbody tr:nth-child(even) {\n",
       "            background-color: #f5f5f5;\n",
       "        }\n",
       "        .dataframe tbody tr:hover {\n",
       "            background-color: #e8eaf6; /* Resaltado suave al pasar el mouse */\n",
       "            cursor: pointer;\n",
       "        }\n",
       "        .dataframe td {\n",
       "            text-align: right;\n",
       "        }\n",
       "        /* Alinear a la izquierda columnas de texto */\n",
       "        .dataframe td:nth-child(2), .dataframe td:nth-child(3) {\n",
       "            text-align: left;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def aplicar_estilo_bancario():\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "        .dataframe {\n",
    "            border-collapse: collapse;\n",
    "            border: 2px solid #1a237e; /* Azul Marino Bancario */\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            font-size: 12px;\n",
    "        }\n",
    "        .dataframe thead {\n",
    "            background-color: #1a237e;\n",
    "            color: white;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .dataframe th, .dataframe td {\n",
    "            padding: 10px 15px;\n",
    "            border: 1px solid #e0e0e0;\n",
    "        }\n",
    "        .dataframe tbody tr:nth-child(even) {\n",
    "            background-color: #f5f5f5;\n",
    "        }\n",
    "        .dataframe tbody tr:hover {\n",
    "            background-color: #e8eaf6; /* Resaltado suave al pasar el mouse */\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        .dataframe td {\n",
    "            text-align: right;\n",
    "        }\n",
    "        /* Alinear a la izquierda columnas de texto */\n",
    "        .dataframe td:nth-child(2), .dataframe td:nth-child(3) {\n",
    "            text-align: left;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(style))\n",
    "\n",
    "aplicar_estilo_bancario()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208da8e",
   "metadata": {},
   "source": [
    "## Paso 1: Configuraci√≥n de Estilos Visuales\n",
    "\n",
    "Aplica estilos CSS personalizados a los DataFrames para que se visualicen con colores bancarios. Esto mejora la legibilidad de los datos durante el an√°lisis exploratorio.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Encabezados con fondo azul marino (#1a237e)\n",
    "- Filas alternas con fondo gris para mejor contraste\n",
    "- Efecto hover para interactividad\n",
    "- Fuente Segoe UI con tama√±o optimizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b7a4da",
   "metadata": {},
   "source": [
    "## Paso 2: Importaci√≥n de Librer√≠as Requeridas\n",
    "\n",
    "Carga todas las dependencias necesarias para el procesamiento ETL:\n",
    "\n",
    "| Librer√≠a | Prop√≥sito |\n",
    "|----------|----------|\n",
    "| `pandas` | Manipulaci√≥n y an√°lisis de datos (DataFrames) |\n",
    "| `numpy` | Operaciones num√©ricas y generaci√≥n de datos aleatorios |\n",
    "| `datetime` | Manejo de fechas y c√°lculos temporales |\n",
    "| `faker` | Generaci√≥n de datos sint√©ticos realistas |\n",
    "| `sqlalchemy` | ORM y conexi√≥n con PostgreSQL |\n",
    "| `dotenv` | Carga segura de credenciales desde archivo `.env` |\n",
    "| `urllib.parse` | Codificaci√≥n de contrase√±as con caracteres especiales |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "33e49beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "from sqlalchemy import create_engine, text, MetaData, Table, select\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import urllib.parse\n",
    "import logging\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurar logging estructurado\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../logs/etl_clientes.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d78466",
   "metadata": {},
   "source": [
    "## Paso 3: Configuraci√≥n de Par√°metros Globales\n",
    "\n",
    "Define las variables que controlan el comportamiento del notebook:\n",
    "\n",
    "**Par√°metros de Datos:**\n",
    "- `N_CLIENTES = 100`: Cantidad de clientes sint√©ticos a generar\n",
    "- `fake = Faker(['es_MX'])`: Generador con localizaci√≥n en espa√±ol mexicano\n",
    "\n",
    "**Esquemas y Tablas en PostgreSQL:**\n",
    "- **Zona Raw (ZR):** `zr_cli.zr_fake_cli_datos_clientes` (datos sin transformar)\n",
    "- **Zona Curada (ZC):** `zc_cli.zc_cli_datos_clientes` (datos normalizados)\n",
    "- **Zona Productiva (ZP):** `zp.td_datos_clientes` (dimensi√≥n final de clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ccafccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros del POC\n",
    "N_CLIENTES = 500\n",
    "# Inicializamos Faker con localizaci√≥n en espa√±ol\n",
    "fake = Faker(['es_MX'])\n",
    "# Nombres para objetos \n",
    "#################################\n",
    "## ZONA RAW\n",
    "#################################\n",
    "\n",
    "nombre_esquema_zr_cli = 'zr_cli'\n",
    "nombre_tabla_zr_cli = 'zr_fake_cli_datos_clientes'\n",
    "\n",
    "#################################\n",
    "## ZONA CURADA\n",
    "#################################\n",
    "\n",
    "nombre_esquema_zc_cli = 'zc_cli'\n",
    "nombre_tabla_zc_cli = 'zc_cli_datos_clientes'\n",
    "\n",
    "#################################\n",
    "## ZONA PRODUCTIVA\n",
    "#################################\n",
    "\n",
    "nombre_esquema_zp = 'zp'\n",
    "nombre_tabla_zp_cli = 'td_datos_clientes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f09ff",
   "metadata": {},
   "source": [
    "## Paso 4: Conexi√≥n a PostgreSQL\n",
    "\n",
    "Establece la conexi√≥n segura con la base de datos PostgreSQL usando credenciales del archivo `.env`.\n",
    "\n",
    "**Proceso:**\n",
    "1. Carga variables de entorno (DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME)\n",
    "2. Codifica la contrase√±a con `urllib.parse.quote_plus()` para manejar caracteres especiales\n",
    "3. Crea engine de SQLAlchemy con la URL codificada\n",
    "4. Valida la conexi√≥n con un intento de conexi√≥n\n",
    "\n",
    "**Ejemplo de `.env`:**\n",
    "```\n",
    "DB_USER=usuario\n",
    "DB_PASSWORD=contrase√±a@especial.123\n",
    "DB_HOST=localhost\n",
    "DB_PORT=5432\n",
    "DB_NAME=banco_poc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3a9bc631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:17:59,688 - __main__ - INFO - ‚úÖ Variables de entorno cargadas correctamente\n",
      "2026-02-21 19:17:59,743 - __main__ - INFO - ‚úÖ Conexi√≥n exitosa con PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "# Forzar recarga del .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "try:\n",
    "    # Validar que existan las credenciales necesarias\n",
    "    user = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASSWORD\")\n",
    "    host = os.getenv(\"DB_HOST\")\n",
    "    port = os.getenv(\"DB_PORT\")\n",
    "    db = os.getenv(\"DB_NAME\")\n",
    "    \n",
    "    # Validar credenciales no nulas\n",
    "    if not all([user, password, host, port, db]):\n",
    "        missing = [k for k, v in {\n",
    "            'DB_USER': user,\n",
    "            'DB_PASSWORD': password,\n",
    "            'DB_HOST': host,\n",
    "            'DB_PORT': port,\n",
    "            'DB_NAME': db\n",
    "        }.items() if not v]\n",
    "        raise ValueError(f\"Variables de entorno faltantes: {', '.join(missing)}\")\n",
    "    \n",
    "    logger.info(\"‚úÖ Variables de entorno cargadas correctamente\")\n",
    "    \n",
    "    # Codificar la contrase√±a para caracteres especiales\n",
    "    password_encoded = urllib.parse.quote_plus(password)\n",
    "    \n",
    "    # Crear engine con par√°metros de seguridad\n",
    "    engine = create_engine(\n",
    "        f'postgresql://{user}:{password_encoded}@{host}:{port}/{db}',\n",
    "        connect_args={\n",
    "            'connect_timeout': 10,\n",
    "            'sslmode': 'prefer'\n",
    "        },\n",
    "        echo=False\n",
    "    )\n",
    "    \n",
    "    # Probar conexi√≥n\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"SELECT 1\"))\n",
    "    logger.info(\"‚úÖ Conexi√≥n exitosa con PostgreSQL\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    logger.error(f\"‚ùå Error de configuraci√≥n: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error al conectar a BD: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a4413f",
   "metadata": {},
   "source": [
    "## Paso 5: Generaci√≥n de Datos Sint√©ticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c45de0",
   "metadata": {},
   "source": [
    "### Paso 5a: Generaci√≥n de Dataset de Clientes Sint√©tico\n",
    "\n",
    "Crea 100 registros de clientes con datos realistas usando Faker.\n",
    "\n",
    "**L√≥gica de Generaci√≥n:**\n",
    "\n",
    "**1. Funci√≥n `generar_id_negocio(tipo)`:**\n",
    "- C√©dula: 10 d√≠gitos aleatorios\n",
    "- RUC: 10 d√≠gitos + sufijo '001' (est√°ndar ecuatoriano)\n",
    "- Pasaporte: 'P' + 8 d√≠gitos aleatorios\n",
    "\n",
    "**2. Dimensi√≥n de Clientes (100 registros):**\n",
    "- `cliente_id`: Secuencial 1000-1099\n",
    "- `codigo_unico_cliente`: Formato CUS-XXXXX\n",
    "- `nombre`: Generado con Faker en espa√±ol mexicano\n",
    "- `email`: Correos generados (ascii free email)\n",
    "- `telefono`: N√∫meros telef√≥nicos generados\n",
    "- `tipo_identificacion`: 80% C√©dula, 15% RUC, 5% Pasaporte\n",
    "- `identificacion`: ID √∫nico seg√∫n tipo\n",
    "- `segmento`: RETAIL (40%), CORPORATIVO, PYME, WEALTH\n",
    "- `provincia`: Pichincha, Guayas, Azuay, Manab√≠, Loja\n",
    "- `ciudad`: Quito, Guayaquil, Cuenca, Manta\n",
    "- `fecha_registro`: Aleatorio en √∫ltimos 5 a√±os\n",
    "- `score_crediticio`: Entero entre 300 y 1000\n",
    "\n",
    "**3. Campos de Auditor√≠a:**\n",
    "- `periodo`: Formato YYYYMM (fecha actual)\n",
    "- `fecha_proceso`: Fecha actual (solo fecha)\n",
    "- `fecha_ingesta`: Timestamp completo con microsegundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fdd2973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:17:59,782 - __main__ - INFO - Iniciando generaci√≥n de 500 clientes sint√©ticos\n",
      "2026-02-21 19:17:59,868 - __main__ - INFO - ‚úÖ 500 clientes generados exitosamente\n",
      "2026-02-21 19:17:59,870 - __main__ - INFO -   - IDs √∫nicos verificados: True\n",
      "2026-02-21 19:17:59,873 - __main__ - INFO -   - Sin valores NULL: True\n",
      "2026-02-21 19:17:59,889 - __main__ - INFO - Campos de auditor√≠a agregados para per√≠odo 20260221\n",
      "2026-02-21 19:17:59,893 - __main__ - INFO - Shape del DataFrame: (500, 15)\n"
     ]
    }
   ],
   "source": [
    "def generar_dataset_clientes():\n",
    "    \"\"\"\n",
    "    Genera dataset de clientes sint√©ticos con datos realistas.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con 100 clientes y campos de auditor√≠a\n",
    "        \n",
    "    Validaciones:\n",
    "        - IDs √∫nicos verificados\n",
    "        - Emails con formato v√°lido\n",
    "        - Scores en rango v√°lido (300-1000)\n",
    "        - Sin valores NULL\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    Faker.seed(42)\n",
    "    logger.info(f\"Iniciando generaci√≥n de {N_CLIENTES} clientes sint√©ticos\")\n",
    "    \n",
    "    try:\n",
    "        def generar_id_negocio(tipo: str) -> str:\n",
    "            \"\"\"\n",
    "            Genera ID de negocio seg√∫n tipo.\n",
    "            \n",
    "            Args:\n",
    "                tipo: C√âDULA, RUC o PASAPORTE\n",
    "                \n",
    "            Returns:\n",
    "                str: ID √∫nico formateado\n",
    "            \"\"\"\n",
    "            if tipo == 'C√âDULA':\n",
    "                return ''.join(np.random.choice(list('0123456789'), 10))\n",
    "            elif tipo == 'RUC':\n",
    "                return ''.join(np.random.choice(list('0123456789'), 10)) + '001'\n",
    "            else:\n",
    "                return 'P' + ''.join(np.random.choice(list('0123456789'), 8))\n",
    "\n",
    "        # Generar tipos de ID con distribuci√≥n realista\n",
    "        tipos_id = np.random.choice(\n",
    "            ['C√âDULA', 'RUC', 'PASAPORTE'], \n",
    "            N_CLIENTES, \n",
    "            p=[0.8, 0.15, 0.05]\n",
    "        )\n",
    "        \n",
    "        # Crear DataFrame con datos\n",
    "        clientes = pd.DataFrame({\n",
    "            'cliente_id': range(1000, 1000 + N_CLIENTES),\n",
    "            'codigo_unico_cliente': [f\"CUS-{i:05d}\" for i in range(1, N_CLIENTES + 1)],\n",
    "            'nombre': [fake.name().upper() for _ in range(N_CLIENTES)],\n",
    "            'email': [fake.ascii_free_email() for _ in range(N_CLIENTES)],\n",
    "            'telefono': [fake.phone_number() for _ in range(N_CLIENTES)],\n",
    "            'tipo_identificacion': tipos_id,\n",
    "            'identificacion': [generar_id_negocio(t) for t in tipos_id],\n",
    "            'segmento': np.random.choice(['RETAIL', 'CORPORATIVO', 'PYME', 'WEALTH'], N_CLIENTES),\n",
    "            'provincia': np.random.choice(['Pichincha', 'Guayas', 'Azuay', 'Manab√≠', 'Loja'], N_CLIENTES),\n",
    "            'ciudad': np.random.choice(['Quito', 'Guayaquil', 'Cuenca', 'Manta'], N_CLIENTES),\n",
    "            'fecha_registro': [fake.date_between(start_date='-5y', end_date='today') for _ in range(N_CLIENTES)],\n",
    "            'score_crediticio': np.random.randint(300, 1000, N_CLIENTES)\n",
    "        })\n",
    "        \n",
    "        # Validaciones de calidad de datos\n",
    "        assert len(clientes) == N_CLIENTES, f\"Cantidad de registros incorrecta: {len(clientes)}\"\n",
    "        assert clientes['cliente_id'].is_unique, \"IDs de cliente duplicados\"\n",
    "        assert clientes['codigo_unico_cliente'].is_unique, \"C√≥digos √∫nicos duplicados\"\n",
    "        assert clientes.isnull().sum().sum() == 0, \"Hay valores NULL en los datos\"\n",
    "        assert (clientes['score_crediticio'] >= 300).all(), \"Scores por debajo de 300\"\n",
    "        assert (clientes['score_crediticio'] < 1000).all(), \"Scores fuera de rango\"\n",
    "        \n",
    "        logger.info(f\"‚úÖ {N_CLIENTES} clientes generados exitosamente\")\n",
    "        logger.info(f\"  - IDs √∫nicos verificados: {clientes['cliente_id'].is_unique}\")\n",
    "        logger.info(f\"  - Sin valores NULL: {clientes.isnull().sum().sum() == 0}\")\n",
    "        \n",
    "        return clientes\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        logger.error(f\"‚ùå Validaci√≥n de datos fallida: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error al generar dataset de clientes: {e}\")\n",
    "        raise\n",
    "\n",
    "df_clientes = generar_dataset_clientes()\n",
    "\n",
    "# Agregar campos de auditor√≠a\n",
    "try:\n",
    "    fechaActual = pd.Timestamp.now()\n",
    "    df_clientes['periodo'] = fechaActual.strftime('%Y%m')\n",
    "    df_clientes['fecha_proceso'] = fechaActual.date()\n",
    "    df_clientes['fecha_ingesta'] = fechaActual\n",
    "    \n",
    "    logger.info(f\"Campos de auditor√≠a agregados para per√≠odo {fechaActual.strftime('%Y%m%d')}\")\n",
    "    logger.info(f\"Shape del DataFrame: {df_clientes.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error al agregar campos de auditor√≠a: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5075912",
   "metadata": {},
   "source": [
    "## Paso 6: Exportaci√≥n a CSV - Zona Raw\n",
    "\n",
    "Guarda el dataset sin transformar en archivo CSV para auditor√≠a y respaldo.\n",
    "\n",
    "**Destino:** `data/raw/zr_fake_cli_datos_clientes.csv`\n",
    "\n",
    "**Prop√≥sito de la Zona Raw:**\n",
    "- Mantener copia exacta de datos originales generados\n",
    "- Facilitar auditor√≠a de cambios posteriores\n",
    "- Permitir reintentos de procesamiento si falla la transformaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3f42baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:17:59,924 - __main__ - INFO - ‚úÖ Archivo guardado: ../data/raw/zr_fake_cli_datos_clientes.csv (86.94 KB)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Crear directorio si no existe\n",
    "    raw_path = Path('../data/raw')\n",
    "    raw_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Guardar archivo con validaci√≥n\n",
    "    csv_path = raw_path / f'{nombre_tabla_zr_cli}.csv'\n",
    "    df_clientes.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Validar archivo creado\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Archivo no se cre√≥: {csv_path}\")\n",
    "    \n",
    "    file_size = csv_path.stat().st_size / 1024  # KB\n",
    "    logger.info(f\"‚úÖ Archivo guardado: {csv_path} ({file_size:.2f} KB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error al exportar CSV (Raw): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1e482",
   "metadata": {},
   "source": [
    "## Paso 7: Funci√≥n Auxiliar para Carga en PostgreSQL\n",
    "\n",
    "Define `cargar_datos_postgresql()` para persistir datos en diferentes esquemas.\n",
    "\n",
    "**Par√°metros:**\n",
    "- `df`: DataFrame a cargar\n",
    "- `nombre_esquema`: Schema destino (zr_cli, zc_cli, zp)\n",
    "- `nombre_tabla`: Tabla destino\n",
    "- `primary_key_column`: Columna clave primaria\n",
    "\n",
    "**L√≥gica:**\n",
    "1. Carga DataFrame con `to_sql()` en modo 'replace' (DROP + CREATE)\n",
    "2. Define clave primaria en la tabla creada\n",
    "3. Manejo robusto de excepciones\n",
    "\n",
    "**Nota:** Usa 'replace' para POC; en producci√≥n usar 'append' + particionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bc3de5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos_postgresql(df: pd.DataFrame, nombre_esquema: str, nombre_tabla: str, primary_key_column: str) -> bool:\n",
    "    \"\"\"\n",
    "    Carga datos en PostgreSQL con validaci√≥n y manejo de errores.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame a cargar\n",
    "        nombre_esquema: Schema destino\n",
    "        nombre_tabla: Tabla destino\n",
    "        primary_key_column: Columna para clave primaria\n",
    "        \n",
    "    Returns:\n",
    "        bool: True si la carga fue exitosa\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Si los par√°metros son inv√°lidos\n",
    "        Exception: Si hay error en la carga\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar inputs\n",
    "        if df.empty:\n",
    "            raise ValueError(\"DataFrame vac√≠o\")\n",
    "        if not isinstance(nombre_esquema, str) or not isinstance(nombre_tabla, str):\n",
    "            raise ValueError(\"Nombre de esquema o tabla inv√°lido\")\n",
    "        \n",
    "        # Validar que la columna PK existe\n",
    "        if primary_key_column.strip('\"') not in df.columns:\n",
    "            raise ValueError(f\"Columna PK no existe: {primary_key_column}\")\n",
    "        \n",
    "        logger.info(f\"Iniciando carga: {nombre_esquema}.{nombre_tabla}\")\n",
    "        logger.info(f\"  - Registros: {len(df)}\")\n",
    "        logger.info(f\"  - Columnas: {df.shape[1]}\")\n",
    "        \n",
    "        # Carga a PostgreSQL\n",
    "        df.to_sql(nombre_tabla, engine, schema=nombre_esquema, if_exists='replace', index=False)\n",
    "        logger.info(f\"‚úÖ Tabla creada: {nombre_esquema}.{nombre_tabla}\")\n",
    "        \n",
    "        # Agregar clave primaria\n",
    "        with engine.connect() as con:\n",
    "            query = text(f'ALTER TABLE {nombre_esquema}.{nombre_tabla} ADD PRIMARY KEY ({primary_key_column});')\n",
    "            con.execute(query)\n",
    "            con.commit()\n",
    "        \n",
    "        logger.info(f\"‚úÖ Clave primaria agregada: {primary_key_column}\")\n",
    "        logger.info(f\"‚úÖ Carga completada exitosamente\")\n",
    "        return True\n",
    "        \n",
    "    except ValueError as e:\n",
    "        logger.error(f\"‚ùå Error de validaci√≥n: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error al cargar en PostgreSQL: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7de61f",
   "metadata": {},
   "source": [
    "## Paso 8: Carga a PostgreSQL - Zona Raw\n",
    "\n",
    "Inserta los datos sin transformar en la tabla `zr_cli.zr_fake_cli_datos_clientes`.\n",
    "\n",
    "**Resultado:**\n",
    "- Tabla con 100 registros de clientes\n",
    "- Clave primaria: cliente_id\n",
    "- Esquema: zr_cli (Zona Raw Clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dc7a2090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,007 - __main__ - INFO - Cargando datos a Zona Raw...\n",
      "2026-02-21 19:18:00,008 - __main__ - INFO - Iniciando carga: zr_cli.zr_fake_cli_datos_clientes\n",
      "2026-02-21 19:18:00,018 - __main__ - INFO -   - Registros: 500\n",
      "2026-02-21 19:18:00,019 - __main__ - INFO -   - Columnas: 15\n",
      "2026-02-21 19:18:00,209 - __main__ - INFO - ‚úÖ Tabla creada: zr_cli.zr_fake_cli_datos_clientes\n",
      "2026-02-21 19:18:00,221 - __main__ - INFO - ‚úÖ Clave primaria agregada: cliente_id\n",
      "2026-02-21 19:18:00,225 - __main__ - INFO - ‚úÖ Carga completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(f\"Cargando datos a Zona Raw...\")\n",
    "    cargar_datos_postgresql(\n",
    "        df_clientes,\n",
    "        nombre_esquema_zr_cli,\n",
    "        nombre_tabla_zr_cli,\n",
    "        'cliente_id'\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Fallo en carga a Zona Raw: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890460a8",
   "metadata": {},
   "source": [
    "## Paso 9: Transformaci√≥n a Zona Curada (ZC)\n",
    "\n",
    "Normaliza los datos aplicando reglas de negocio y estandarizaci√≥n de nomenclatura bancaria.\n",
    "\n",
    "**Proceso:**\n",
    "\n",
    "**1. Extracci√≥n desde Raw:**\n",
    "- Refleja tabla desde `zr_cli.zr_fake_cli_datos_clientes` usando SQLAlchemy MetaData\n",
    "- Lee estructura y datos del archivo original\n",
    "\n",
    "**2. Mapeo de Columnas (Nomenclatura bancaria):**\n",
    "- `periodo` ‚Üí `codigoPeriodo`\n",
    "- `cliente_id` ‚Üí `codigoSecuencialCliente`\n",
    "- `codigo_unico_cliente` ‚Üí `codigoIdentificacionCliente`\n",
    "- `tipo_identificacion` ‚Üí `tipoIdentificacionCliente`\n",
    "- `identificacion` ‚Üí `numeroIdentificacionCliente`\n",
    "- `nombre` ‚Üí `nombreCompletoCliente`\n",
    "- `email` ‚Üí `correoElectronicoCliente`\n",
    "- `telefono` ‚Üí `telefonoCliente`\n",
    "- `segmento` ‚Üí `segmentoCliente`\n",
    "- `score_crediticio` ‚Üí `scoreCrediticioCliente`\n",
    "- `provincia` ‚Üí `provinciaCliente`\n",
    "- `ciudad` ‚Üí `ciudadCliente`\n",
    "- `fecha_registro` ‚Üí `fechaRegistroCliente`\n",
    "- `fecha_proceso` ‚Üí `periodo`\n",
    "\n",
    "**3. Transformaciones de Datos:**\n",
    "- Convierte a MAY√öSCULAS: provincia, ciudad, tipo_identificaci√≥n\n",
    "- Limpia espacios en blanco: `.str.strip()`\n",
    "- Reordena columnas en orden l√≥gico\n",
    "\n",
    "**4. Campos de Auditor√≠a:**\n",
    "- Agrega `fechaIngesta`: Timestamp completo\n",
    "\n",
    "**Resultado:** DataFrame normalizado con nomenclatura bancaria est√°ndar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d8074d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,258 - __main__ - INFO - Iniciando transformaci√≥n a Zona Curada\n",
      "2026-02-21 19:18:00,283 - __main__ - INFO - ‚úÖ Tabla reflejada: zr_cli.zr_fake_cli_datos_clientes\n",
      "2026-02-21 19:18:00,311 - __main__ - INFO - ‚úÖ 500 registros cargados desde PostgreSQL\n",
      "2026-02-21 19:18:00,319 - __main__ - INFO - ‚úÖ Columnas renombradas: 14 campos mapeados\n",
      "2026-02-21 19:18:00,324 - __main__ - INFO - ‚úÖ Transformaciones aplicadas\n",
      "2026-02-21 19:18:00,345 - __main__ - INFO - ‚úÖ Transformaci√≥n completada. Shape: (500, 15)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"Iniciando transformaci√≥n a Zona Curada\")\n",
    "    \n",
    "    # Crear un objeto MetaData\n",
    "    metadata = MetaData()\n",
    "    \n",
    "    # Reflejar la tabla desde PostgreSQL\n",
    "    tabla_clientes = Table(\n",
    "        nombre_tabla_zr_cli, \n",
    "        metadata, \n",
    "        autoload_with=engine, \n",
    "        schema=nombre_esquema_zr_cli\n",
    "    )\n",
    "    logger.info(f\"‚úÖ Tabla reflejada: {nombre_esquema_zr_cli}.{nombre_tabla_zr_cli}\")\n",
    "    \n",
    "    # Construir consulta\n",
    "    stmt = select(tabla_clientes)\n",
    "    \n",
    "    # Cargar en Pandas\n",
    "    with engine.connect() as con:\n",
    "        df_db_clientes = pd.read_sql(stmt, con)\n",
    "    logger.info(f\"‚úÖ {len(df_db_clientes)} registros cargados desde PostgreSQL\")\n",
    "    \n",
    "    # Mapeo de columnas\n",
    "    mapping = {\n",
    "        'periodo': 'codigoPeriodo', \n",
    "        'cliente_id': 'codigoSecuencialCliente',\n",
    "        'codigo_unico_cliente': 'codigoIdentificacionCliente',\n",
    "        'tipo_identificacion': 'tipoIdentificacionCliente',\n",
    "        'identificacion': 'numeroIdentificacionCliente',\n",
    "        'nombre': 'nombreCompletoCliente',\n",
    "        'email': 'correoElectronicoCliente',\n",
    "        'telefono': 'telefonoCliente',\n",
    "        'segmento': 'segmentoCliente',\n",
    "        'score_crediticio': 'scoreCrediticioCliente',\n",
    "        'provincia': 'provinciaCliente',\n",
    "        'ciudad': 'ciudadCliente',\n",
    "        'fecha_registro': 'fechaRegistroCliente',\n",
    "        'fecha_proceso': 'periodo'\n",
    "    }\n",
    "    \n",
    "    df_db_clientes = df_db_clientes.rename(columns=mapping)\n",
    "    logger.info(f\"‚úÖ Columnas renombradas: {len(mapping)} campos mapeados\")\n",
    "    \n",
    "    # Transformaciones con validaci√≥n\n",
    "    columnas_upper = ['provinciaCliente', 'ciudadCliente', 'tipoIdentificacionCliente']\n",
    "    for col in columnas_upper:\n",
    "        if col in df_db_clientes.columns:\n",
    "            # Manejar valores NULL\n",
    "            df_db_clientes[col] = df_db_clientes[col].fillna('').str.upper().str.strip()\n",
    "    \n",
    "    # Limpiar espacios en blanco\n",
    "    columnas_string = ['codigoIdentificacionCliente', 'nombreCompletoCliente', \n",
    "                       'correoElectronicoCliente', 'segmentoCliente']\n",
    "    for col in columnas_string:\n",
    "        if col in df_db_clientes.columns:\n",
    "            df_db_clientes[col] = df_db_clientes[col].fillna('').str.strip()\n",
    "    \n",
    "    logger.info(\"‚úÖ Transformaciones aplicadas\")\n",
    "    \n",
    "    # Reordenar columnas\n",
    "    columnas_finales = [\n",
    "        'codigoSecuencialCliente',\n",
    "        'codigoPeriodo',\n",
    "        'codigoIdentificacionCliente',\n",
    "        'tipoIdentificacionCliente',\n",
    "        'numeroIdentificacionCliente',\n",
    "        'nombreCompletoCliente',\n",
    "        'correoElectronicoCliente',\n",
    "        'telefonoCliente',\n",
    "        'segmentoCliente',\n",
    "        'scoreCrediticioCliente',\n",
    "        'provinciaCliente',\n",
    "        'ciudadCliente',\n",
    "        'fechaRegistroCliente',\n",
    "        'periodo'\n",
    "    ]\n",
    "    \n",
    "    df_db_clientes = df_db_clientes[columnas_finales]\n",
    "    df_db_clientes['fechaIngesta'] = fechaActual\n",
    "    \n",
    "    logger.info(f\"‚úÖ Transformaci√≥n completada. Shape: {df_db_clientes.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error en transformaci√≥n a ZC: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19818950",
   "metadata": {},
   "source": [
    "## Paso 10: Exportaci√≥n a CSV - Zona Curada\n",
    "\n",
    "Guarda los datos transformados en archivo CSV.\n",
    "\n",
    "**Destino:** `data/curada/zc_cli_datos_clientes.csv`\n",
    "\n",
    "**Prop√≥sito:**\n",
    "- Respaldo de datos curados\n",
    "- Verificaci√≥n manual de transformaciones\n",
    "- Punto de referencia para auditor√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d60938fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,441 - __main__ - INFO - ‚úÖ Archivo guardado: ../data/curada/zc_cli_datos_clientes.csv (87.05 KB)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Crear directorio si no existe\n",
    "    curada_path = Path('../data/curada')\n",
    "    curada_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_path = curada_path / f'{nombre_tabla_zc_cli}.csv'\n",
    "    df_db_clientes.to_csv(csv_path, index=False)\n",
    "    \n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Archivo no se cre√≥: {csv_path}\")\n",
    "    \n",
    "    file_size = csv_path.stat().st_size / 1024\n",
    "    logger.info(f\"‚úÖ Archivo guardado: {csv_path} ({file_size:.2f} KB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error al exportar CSV (Curada): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909cbdb",
   "metadata": {},
   "source": [
    "## Paso 11: Carga a PostgreSQL - Zona Curada\n",
    "\n",
    "Inserta los datos transformados en la tabla `zc_cli.zc_cli_datos_clientes`.\n",
    "\n",
    "**Tabla destino:** `zc_cli.zc_cli_datos_clientes`\n",
    "**Clave Primaria:** codigoSecuencialCliente\n",
    "\n",
    "Esta es la zona de an√°lisis intermedia con datos ya normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bac97e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,500 - __main__ - INFO - Cargando datos a Zona Curada...\n",
      "2026-02-21 19:18:00,506 - __main__ - INFO - Iniciando carga: zc_cli.zc_cli_datos_clientes\n",
      "2026-02-21 19:18:00,507 - __main__ - INFO -   - Registros: 500\n",
      "2026-02-21 19:18:00,508 - __main__ - INFO -   - Columnas: 15\n",
      "2026-02-21 19:18:00,670 - __main__ - INFO - ‚úÖ Tabla creada: zc_cli.zc_cli_datos_clientes\n",
      "2026-02-21 19:18:00,681 - __main__ - INFO - ‚úÖ Clave primaria agregada: \"codigoSecuencialCliente\"\n",
      "2026-02-21 19:18:00,684 - __main__ - INFO - ‚úÖ Carga completada exitosamente\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(f\"Cargando datos a Zona Curada...\")\n",
    "    cargar_datos_postgresql(\n",
    "        df_db_clientes,\n",
    "        nombre_esquema_zc_cli,\n",
    "        nombre_tabla_zc_cli,\n",
    "        '\"codigoSecuencialCliente\"'\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Fallo en carga a Zona Curada: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f3efa",
   "metadata": {},
   "source": [
    "## Paso 12: Generaci√≥n de Dimensi√≥n de Clientes Optimizada\n",
    "\n",
    "Selecciona y reordena columnas para crear dimensi√≥n final optimizada para an√°lisis.\n",
    "\n",
    "**Columnas Seleccionadas (12 campos):**\n",
    "1. `codigoSecuencialCliente` - ID secuencial\n",
    "2. `codigoPeriodo` - Per√≠odo YYYYMM\n",
    "3. `codigoIdentificacionCliente` - C√≥digo √∫nico cliente\n",
    "4. `tipoIdentificacionCliente` - Tipo de ID\n",
    "5. `numeroIdentificacionCliente` - N√∫mero de ID\n",
    "6. `nombreCompletoCliente` - Nombre completo\n",
    "7. `segmentoCliente` - Segmento cliente\n",
    "8. `scoreCrediticioCliente` - Score crediticio\n",
    "9. `provinciaCliente` - Provincia\n",
    "10. `ciudadCliente` - Ciudad\n",
    "11. `fechaRegistroCliente` - Fecha de registro\n",
    "12. `periodo` - Per√≠odo YYYYMMDD\n",
    "\n",
    "**Prop√≥sito:** \n",
    "- Reducir columnas innecesarias (email, tel√©fono, etc.)\n",
    "- Optimizar performance de consultas anal√≠ticas\n",
    "- Crear dimensi√≥n lista para joins con hechos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ba504c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,707 - __main__ - INFO - Generando dimensi√≥n optimizada de clientes\n",
      "2026-02-21 19:18:00,715 - __main__ - INFO - ‚úÖ Dimensi√≥n generada: (500, 12)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"Generando dimensi√≥n optimizada de clientes\")\n",
    "    \n",
    "    columnas_dimension = [\n",
    "        'codigoSecuencialCliente',\n",
    "        'codigoPeriodo',\n",
    "        'codigoIdentificacionCliente',\n",
    "        'tipoIdentificacionCliente',\n",
    "        'numeroIdentificacionCliente',\n",
    "        'nombreCompletoCliente',\n",
    "        'segmentoCliente',\n",
    "        'scoreCrediticioCliente',\n",
    "        'provinciaCliente',\n",
    "        'ciudadCliente',\n",
    "        'fechaRegistroCliente',\n",
    "        'periodo'\n",
    "    ]\n",
    "    \n",
    "    # Validar que todas las columnas existen\n",
    "    cols_faltantes = [c for c in columnas_dimension if c not in df_db_clientes.columns]\n",
    "    if cols_faltantes:\n",
    "        raise ValueError(f\"Columnas faltantes: {cols_faltantes}\")\n",
    "    \n",
    "    df_db_clientes = df_db_clientes[columnas_dimension]\n",
    "    logger.info(f\"‚úÖ Dimensi√≥n generada: {df_db_clientes.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error al generar dimensi√≥n: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c184c",
   "metadata": {},
   "source": [
    "## Paso 13: Exportaci√≥n a CSV - Zona Productiva\n",
    "\n",
    "Guarda la dimensi√≥n de clientes optimizada en archivo CSV.\n",
    "\n",
    "**Destino:** `data/productiva/td_datos_clientes.csv`\n",
    "\n",
    "**Contenido:** \n",
    "Dimensi√≥n de clientes con 12 columnas esenciales.\n",
    "\n",
    "**Prop√≥sito:**\n",
    "- Dataset final para an√°lisis y reportes\n",
    "- Base para consolidaci√≥n con tablas de hechos (inversiones)\n",
    "- Auditor√≠a de dimensi√≥n entregada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "79d6587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,772 - __main__ - INFO - ‚úÖ Archivo guardado: ../data/productiva/td_datos_clientes.csv (54.94 KB)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Crear directorio si no existe\n",
    "    productiva_path = Path('../data/productiva')\n",
    "    productiva_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_path = productiva_path / f'{nombre_tabla_zp_cli}.csv'\n",
    "    df_db_clientes.to_csv(csv_path, index=False)\n",
    "    \n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Archivo no se cre√≥: {csv_path}\")\n",
    "    \n",
    "    file_size = csv_path.stat().st_size / 1024\n",
    "    logger.info(f\"‚úÖ Archivo guardado: {csv_path} ({file_size:.2f} KB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error al exportar CSV (Productiva): {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e5c569",
   "metadata": {},
   "source": [
    "## Paso 14: Carga a PostgreSQL - Zona Productiva\n",
    "\n",
    "Inserta la dimensi√≥n final en la tabla `zp.td_datos_clientes` para consultas anal√≠ticas.\n",
    "\n",
    "**Tabla destino:** `zp.td_datos_clientes` (Dimensi√≥n de Clientes)\n",
    "**Registros:** 100 clientes\n",
    "**Clave Primaria:** codigoSecuencialCliente\n",
    "\n",
    "Esta es la tabla consultable para:\n",
    "- Enriquecimiento de datos de inversiones\n",
    "- Reportes de clientes por segmento\n",
    "- An√°lisis de score crediticio\n",
    "- Filtros geogr√°ficos (provincia, ciudad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7c59be77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:00,812 - __main__ - INFO - Cargando datos a Zona Productiva...\n",
      "2026-02-21 19:18:00,816 - __main__ - INFO - Iniciando carga: zp.td_datos_clientes\n",
      "2026-02-21 19:18:00,826 - __main__ - INFO -   - Registros: 500\n",
      "2026-02-21 19:18:00,833 - __main__ - INFO -   - Columnas: 12\n",
      "2026-02-21 19:18:01,078 - __main__ - INFO - ‚úÖ Tabla creada: zp.td_datos_clientes\n",
      "2026-02-21 19:18:01,124 - __main__ - INFO - ‚úÖ Clave primaria agregada: \"codigoSecuencialCliente\"\n",
      "2026-02-21 19:18:01,127 - __main__ - INFO - ‚úÖ Carga completada exitosamente\n",
      "2026-02-21 19:18:01,128 - __main__ - INFO - ‚úÖ Dimensi√≥n de Clientes cargada exitosamente en PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(f\"Cargando datos a Zona Productiva...\")\n",
    "    cargar_datos_postgresql(\n",
    "        df_db_clientes,\n",
    "        nombre_esquema_zp,\n",
    "        nombre_tabla_zp_cli,\n",
    "        '\"codigoSecuencialCliente\"'\n",
    "    )\n",
    "    logger.info(\"‚úÖ Dimensi√≥n de Clientes cargada exitosamente en PostgreSQL\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Fallo en carga a Zona Productiva: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ea28a",
   "metadata": {},
   "source": [
    "## Paso 15: Limpieza y Liberaci√≥n de Recursos\n",
    "\n",
    "Cierra conexiones de base de datos y libera memoria del kernel de Jupyter.\n",
    "\n",
    "**Acciones:**\n",
    "1. **Cierra conexiones PostgreSQL:**\n",
    "   - Busca objetos con m√©todo `.close()` (conexiones DBAPI)\n",
    "   - Busca objetos con m√©todo `.dispose()` (SQLAlchemy engines)\n",
    "\n",
    "2. **Libera DataFrames:**\n",
    "   - Identifica todos los DataFrames en memoria\n",
    "   - Los elimina para liberar RAM\n",
    "\n",
    "3. **Recolecci√≥n de basura:**\n",
    "   - Ejecuta `gc.collect()` para optimizar memoria\n",
    "\n",
    "**Prop√≥sito:** \n",
    "- Evitar memory leaks en Jupyter\n",
    "- Permitir nuevas ejecuciones del notebook sin problemas\n",
    "- Liberar conexiones a PostgreSQL para otros procesos\n",
    "\n",
    "**Resultado:** \"üßπ Memoria RAM optimizada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea13cc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:01,225 - __main__ - INFO - --- Iniciando limpieza de recursos ---\n",
      "2026-02-21 19:18:01,243 - __main__ - INFO - ‚úÖ Conexi√≥n 'conn' cerrada\n",
      "2026-02-21 19:18:01,255 - __main__ - INFO - ‚úÖ Engine 'engine' dispuesto\n",
      "2026-02-21 19:18:01,263 - __main__ - INFO - üîå Conexi√≥n a PostgreSQL cerrada correctamente\n",
      "2026-02-21 19:18:01,274 - __main__ - INFO - Eliminando 2 DataFrames: df_clientes, df_db_clientes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 19:18:01,279 - __main__ - INFO - üóëÔ∏è DataFrames eliminados de la memoria\n",
      "2026-02-21 19:18:01,660 - __main__ - INFO - ‚úÖ Recolecci√≥n de basura completada\n",
      "2026-02-21 19:18:01,663 - __main__ - INFO - üßπ Memoria RAM optimizada\n",
      "2026-02-21 19:18:01,665 - __main__ - INFO - --- Limpieza finalizada ---\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"--- Iniciando limpieza de recursos ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Cerrar conexiones a Bases de Datos\n",
    "    possible_conn_names = ['conn', 'connection', 'db_conn', 'engine']\n",
    "    \n",
    "    for name in possible_conn_names:\n",
    "        if name in globals():\n",
    "            obj = globals()[name]\n",
    "            try:\n",
    "                if hasattr(obj, 'close'):\n",
    "                    obj.close()\n",
    "                    logger.info(f\"‚úÖ Conexi√≥n '{name}' cerrada\")\n",
    "                elif hasattr(obj, 'dispose'):\n",
    "                    obj.dispose()\n",
    "                    logger.info(f\"‚úÖ Engine '{name}' dispuesto\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"‚ö†Ô∏è No se pudo cerrar '{name}': {e}\")\n",
    "    \n",
    "    logger.info(\"üîå Conexi√≥n a PostgreSQL cerrada correctamente\")\n",
    "    \n",
    "    # 2. Eliminar DataFrames para liberar memoria\n",
    "    df_variables = [var for var, obj in globals().items() \n",
    "                    if isinstance(obj, pd.DataFrame) and not var.startswith('_')]\n",
    "    \n",
    "    if df_variables:\n",
    "        logger.info(f\"Eliminando {len(df_variables)} DataFrames: {', '.join(df_variables)}\")\n",
    "        for var in df_variables:\n",
    "            del globals()[var]\n",
    "        logger.info(\"üóëÔ∏è DataFrames eliminados de la memoria\")\n",
    "    else:\n",
    "        logger.info(\"No se encontraron DataFrames para eliminar\")\n",
    "    \n",
    "    # 3. Forzar recolecci√≥n de basura\n",
    "    gc.collect()\n",
    "    logger.info(\"‚úÖ Recolecci√≥n de basura completada\")\n",
    "    logger.info(\"üßπ Memoria RAM optimizada\")\n",
    "    logger.info(\"--- Limpieza finalizada ---\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Error durante limpieza: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc-bancs-inversion-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
